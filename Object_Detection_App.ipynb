{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOcYDZdHOl3Filwglo4GtDP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Install necessary packages\n","!pip install torch torchvision torchaudio  # Ensure PyTorch is installed\n","!pip install gradio  # Install Gradio for the web interface\n","!pip install yolov5  # Install YOLOv5 dependencies"],"metadata":{"id":"J7RJf6Lpcir_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import required libraries\n","import torch\n","import gradio as gr\n","from PIL import Image\n","\n","# Load the pretrained YOLOv5 model\n","model = torch.hub.load('ultralytics/yolov5', 'yolov5x', pretrained=True)\n","\n","# Function to process the image and return detections\n","def detect_objects(image):\n","    # Perform inference on the uploaded image\n","    results = model(image)\n","\n","    # Plot results on the image (YOLOv5 provides results with bounding boxes, class names, and confidence scores)\n","    results_img = results.render()[0]  # Render the detections on the image\n","\n","    # Convert to a PIL Image for compatibility with Gradio\n","    return Image.fromarray(results_img)\n","\n","# Define the Gradio interface\n","interface = gr.Interface(\n","    fn=detect_objects,\n","    inputs=gr.Image(type=\"pil\"),\n","    outputs=gr.Image(type=\"pil\"),\n","    title=\"Object Detection App\",\n","    description=\"Upload an image to detect objects using the YOLOv5 model.\"\n",")\n","\n","# Launch the Gradio app\n","interface.launch()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":729},"id":"Epa2CKGZchG4","executionInfo":{"status":"ok","timestamp":1731164661334,"user_tz":-330,"elapsed":6271,"user":{"displayName":"Shankar M","userId":"10482831461877206419"}},"outputId":"df7cb4e0-8253-483c-bd2e-31d82c3531c2"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n","YOLOv5 ðŸš€ 2024-11-9 Python-3.10.12 torch-2.5.0+cu121 CPU\n","\n","Fusing layers... \n","YOLOv5x summary: 444 layers, 86705005 parameters, 0 gradients, 205.5 GFLOPs\n","Adding AutoShape... \n"]},{"output_type":"stream","name":"stdout","text":["Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://36858091a094d3f7f7.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://36858091a094d3f7f7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":3}]}]}